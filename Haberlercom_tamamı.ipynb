{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Haberlercom-tamamı.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP32SIVVaUef6IJ+qdA0seM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doukansurel/Kod/blob/main/Haberlercom_tamam%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_igXbD72ac0"
      },
      "source": [
        "import os\n",
        "import bs4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "import re\n",
        "import urllib3\n",
        "from pandas import DataFrame\n",
        "import csv\n",
        "import datetime\n",
        "from datetime import datetime, timedelta ,date\n",
        "import concurrent"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L8VjRu44udk"
      },
      "source": [
        "pages = []\n",
        "pages_links = []\n",
        "page_news_links = []"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FvADHz12A9b"
      },
      "source": [
        "def date_creator():\n",
        "  url = \"https://www.haberler.com/arsiv/{}/haberler/s1/\"\n",
        "  num = 1\n",
        "  t1 = datetime(2006,6,1)\n",
        "  t2 = datetime(2021,8,5)                                                             # Genel liinkleri oluşturyor\n",
        "  t= timedelta(days = 1)\n",
        "  dates=np.arange(t1, t2, t).astype(datetime)\n",
        "  for j in dates:\n",
        "    new_url =(url.format(j.strftime('%d-%m-%Y'),num))\n",
        "    pages.append(new_url)\n"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nBkDQwfRrMQ"
      },
      "source": [
        "date_creator()"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRmrVITM6ola"
      },
      "source": [
        "def page_get_link(url):\n",
        "  r = requests.get(url).content\n",
        "  soup = BeautifulSoup(r, \"html.parser\")\n",
        "  #p_count = soup.find(\"div\",{\"class\":\"hbPagination\"}).find_all(\"span\")\n",
        "  array = []\n",
        "  span = \"\"\n",
        "  if not soup.find(\"div\",{\"class\":\"hbPagination\"}) :                                # Linklerin sayfaları ile birlite ayarlıyor\n",
        "    pages_links.append(url)\n",
        "  else :\n",
        "    p_count =soup.find(\"div\",{\"class\":\"hbPagination\"}).find_all(\"span\")\n",
        "    for i in p_count :\n",
        "      span = i.getText()\n",
        "      array.append(span)\n",
        "\n",
        "    page_num = len(array)-1\n",
        "    new_url = url \n",
        "    new_url = new_url.replace(\"s1\",\"s{}\")\n",
        "\n",
        "    for i in range(page_num):\n",
        "      i = str(i+1)\n",
        "      lnk = new_url.format(i)\n",
        "      pages_links.append(lnk)\n"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYhY_Mc8skjy"
      },
      "source": [
        "# for i in pages[:100]:\n",
        "#   page_get_link(i)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O955dN7WZHA6",
        "outputId": "efddea25-0f8e-4d95-8e42-7c5872c2294e"
      },
      "source": [
        "# for i in pages_links[:100]:\n",
        "#   print(i)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.haberler.com/arsiv/01-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/01-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/01-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/01-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/02-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/02-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/02-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/03-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/03-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/04-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/04-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/05-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/05-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/05-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/06-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/06-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/06-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/07-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/07-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/07-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/08-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/08-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/08-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/09-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/09-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/09-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/09-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/10-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/10-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/10-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/11-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/11-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/12-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/12-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/12-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/12-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/13-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/13-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/13-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/13-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/14-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/14-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/14-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/14-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/15-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/15-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/15-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/15-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/16-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/16-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/16-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/16-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/17-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/17-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/18-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/18-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/19-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/19-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/19-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/20-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/20-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/21-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/21-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/21-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/21-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/21-06-2006/haberler/s5/\n",
            "https://www.haberler.com/arsiv/22-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/22-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/22-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/22-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/23-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/23-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/23-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/23-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/24-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/24-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/24-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/25-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/25-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/25-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/26-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/26-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/26-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/27-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/27-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/27-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/28-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/28-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/28-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/28-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/29-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/29-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/29-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/29-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/30-06-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/30-06-2006/haberler/s2/\n",
            "https://www.haberler.com/arsiv/30-06-2006/haberler/s3/\n",
            "https://www.haberler.com/arsiv/30-06-2006/haberler/s4/\n",
            "https://www.haberler.com/arsiv/01-07-2006/haberler/s1/\n",
            "https://www.haberler.com/arsiv/01-07-2006/haberler/s2/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JboDFNbnYHIZ"
      },
      "source": [
        "t1=time.time()\n",
        "with concurrent.futures.ProcessPoolExecutor() as execut:\n",
        "  b_res=[execut.submit(page_get_link,i.strip()) for i in pages]\n",
        "print(time.time()-t1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xntKMeN22Q6x"
      },
      "source": [
        "def haber_get_link(url):\n",
        "  r = requests.get(url).content\n",
        "  soup = BeautifulSoup(r,\"html.parser\")\n",
        "  list = soup.find_all(\"div\",{\"class\":\"box boxStyle color-general\"})\n",
        "                                                                           # tüm sayfalardaki haberlerin linklerini alıyor\n",
        "  for i in list :\n",
        "    href = i.find(\"a\").get(\"href\")\n",
        "    page_news_links.append(href)\n",
        "  \n",
        "  with open (\"haberlercom-Links.txt\",\"a\",encoding=\"utf-8\") as file :\n",
        "    for i in page_news_links:\n",
        "      file.write(i+\"\\n\")"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2tASlON4WcG"
      },
      "source": [
        "# for i in pages_links[:50]:\n",
        "#   haber_get_link(i)\n",
        "t1=time.time()\n",
        "with concurrent.futures.ProcessPoolExecutor() as execut:\n",
        "  b_res=[execut.submit(haber_get_link,i.strip()) for i in pages_links]\n",
        "print(time.time()-t1)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN_Zc0Tj0aLl"
      },
      "source": [
        "def creator(url):\n",
        "  r = requests.get(url).content\n",
        "  soup = BeautifulSoup(r,\"html.parser\")\n",
        "  title = soup.find(\"div\",{\"class\":\"hbptHead\"}).find(\"h1\",{\"class\":\"haber_baslik\"}).getText() \n",
        "  date = soup.find(\"div\",{\"class\":\"hbptHead hbdetaytarihCnt\"}).find(\"time\").getText()\n",
        "  date =date[:15] \n",
        "  categori_array = []\n",
        "  categori = soup.find(\"div\",{\"class\":\"hbptHead hbdetaytarihCnt\"}).find_all(\"a\")\n",
        "  \n",
        "  for i in categori :\n",
        "    categori_array.append(i.getText())                                                      # Her Link içeriğini alır ve yazdırır\n",
        "  cat = categori_array[len(categori_array)-1]  \n",
        "\n",
        "  content_string = \"\"\n",
        "  content = soup.find(\"div\",{\"class\":\"hbptContent haber_metni\"}).find_all(\"p\")\n",
        "  \n",
        "  for i in content:\n",
        "    content_string += i.getText().strip(\"Kaynak: \")\n",
        "  sentence = \"{} ; {} ; {} ; {} ; {}\".format(url,cat,date,title,content_string)\n",
        "\n",
        "  with open(\"haberlercom-Cont.txt\",\"a\",encoding=\"utf-8\")as file:\n",
        "    file.write(sentence+\"\\n\")\n"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ugolhQU1K1q"
      },
      "source": [
        "t1=time.time()\n",
        "with concurrent.futures.ProcessPoolExecutor() as execut:\n",
        "  b_res=[execut.submit(creator,i.strip()) for i in page_news_links]\n",
        "print(time.time()-t1)\n",
        "# for i in page_news_links[:20]:\n",
        "#   creator(i)"
      ],
      "execution_count": 251,
      "outputs": []
    }
  ]
}